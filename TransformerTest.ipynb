{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvyINlKKwaOb"
      },
      "source": [
        "# **CSCI323 Group Assignment**\n",
        "\n",
        "This is our exploration of using Transformers instead of a Naive Bayes classifer as an approach to perform sentiment analysis on a dataset.  \n",
        "\n",
        "Our dataset has been truncated to exclude \"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset/resolve/main/train_df.csv\", due to an error with the file which causes our model tuning to crash. This approximately halves the size of our dataset. However, as we will see, the transformer model is able to achieve very similar accuracy to our Naives Bayes model, while having far less data to train  on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EwqvriVKP3X"
      },
      "source": [
        "## **Data Preparation**\n",
        "\n",
        "### **Loading the dataset**\n",
        "\n",
        "Firstly, we load the data into a pandas dataframe concatenate them into a single dataset. Our dataset is a combination of 2 huggingface datasets consisting of online comments, each pre-labelled with either **Negative(0)**, **Neutral(1)** or **Positive(2)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NEQBqh63KXHN",
        "outputId": "f9937b8c-62ad-44b7-bee3-081810fe4182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text  label sentiment\n",
              "0   9235                         getting cds ready for tour      1   neutral\n",
              "1  16790   MC, happy mother`s day to your mom ;).. love yah      2  positive\n",
              "2  24840  A year from now is graduation....i am pretty s...      0  negative\n",
              "3  20744              because you had chips and sale w/o me      1   neutral\n",
              "4   6414          Great for organising my work life balance      2  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e0dae2d-d3b4-48ed-8d99-ce4e6c4222a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9235</td>\n",
              "      <td>getting cds ready for tour</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16790</td>\n",
              "      <td>MC, happy mother`s day to your mom ;).. love yah</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24840</td>\n",
              "      <td>A year from now is graduation....i am pretty s...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20744</td>\n",
              "      <td>because you had chips and sale w/o me</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6414</td>\n",
              "      <td>Great for organising my work life balance</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e0dae2d-d3b4-48ed-8d99-ce4e6c4222a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e0dae2d-d3b4-48ed-8d99-ce4e6c4222a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e0dae2d-d3b4-48ed-8d99-ce4e6c4222a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89e5b0a6-3b50-4907-a678-fb2d7e82880d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89e5b0a6-3b50-4907-a678-fb2d7e82880d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89e5b0a6-3b50-4907-a678-fb2d7e82880d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_data",
              "summary": "{\n  \"name\": \"df_data\",\n  \"rows\": 41426,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40376,\n        \"samples\": [\n          \"067058825c\",\n          27440,\n          \"9bb948129e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33656,\n        \"samples\": [\n          \" tell zach & jer I said happy birthday!  they seem like cool brothers, youre lucky haha\",\n          \" SC2 will be released before D3  Hopefully!\",\n          \"still needs another 6 hours of sleep\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the dataset\n",
        "#Dataset 1\n",
        "url1 = [\n",
        "    # \"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset/resolve/main/train_df.csv\",\n",
        "    \"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset/resolve/main/test_df.csv\",\n",
        "    \"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset/resolve/main/val_df.csv\"\n",
        "]\n",
        "\n",
        "df_data1 = pd.concat([pd.read_csv(url) for url in url1], ignore_index=True)\n",
        "\n",
        "#Dataset 2\n",
        "url2 = [\n",
        "    \"https://huggingface.co/datasets/mteb/tweet_sentiment_extraction/resolve/main/train.jsonl\",\n",
        "    \"https://huggingface.co/datasets/mteb/tweet_sentiment_extraction/resolve/main/test.jsonl\"\n",
        "]\n",
        "df_data2 = pd.concat([pd.read_json(url, lines=True) for url in url2], ignore_index=True)\n",
        "\n",
        "#Rename df_data2[label_text] to df_data2[sentiment]\n",
        "df_data2.rename(columns={'label_text': 'sentiment'}, inplace=True)\n",
        "\n",
        "#Combine both datasets\n",
        "df_data = pd.concat([df_data1, df_data2], ignore_index=True)\n",
        "\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3G7FGDz9OC"
      },
      "source": [
        "## **Pre-processing**\n",
        "\n",
        "We use the **Natural Language Toolkit(NLTK)** which is a comprehensive library for working with human language data. NLTK provides useful tools for text processing such as tokenization and lemmitization. Here is a quick overview and explanation of the other imports used in this portion of the code:\n",
        "1. The **punkt** tonkenizer is used for dividing a text into a list of words or sentences. This is needed for tokenization tasks.\n",
        "2. A list of **stopwords** like *and*, *is*, *the*, etc is downloaded which is often removed from text data to focus on more meaningful words.\n",
        "3. The **WordNet** database provides a large dictionary of words and their meanings, synonyms and antonymns. This is used for lemmatization where words are reduced to their base forms.\n",
        "4. The **Open Multilingual WordNet** package allows access to WordNet in multiple languages. Our dataset is multilingual so this helps us in multilingual text processing.\n",
        "5. **Words** is a list of English words which is used to filter or validate tokens to ensure that they are real words.\n",
        "6. **word_tokenize** is a function that breaks down text into individual words.\n",
        "7. **WordNetLemmatizer** is a tool that reduces words to their base form, eg *running* to *run*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qRwnbnnKfq2",
        "outputId": "951c8236-f74b-4ba6-964e-c3b07be8f02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/431.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.12.1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('words')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import re\n",
        "!pip install emoji\n",
        "import emoji\n",
        "\n",
        "#Data processing\n",
        "#Convert text to lowercase\n",
        "df_data['text'] = df_data['text'].str.lower()\n",
        "\n",
        "#Function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    if isinstance(text, str):\n",
        "        return re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
        "    else:\n",
        "        return text  # or return an empty string: ''\n",
        "\n",
        "#Apply punctuation removal to the text column\n",
        "df_data['text'] = df_data['text'].apply(remove_punctuation)\n",
        "\n",
        "# Function to convert emojis to text\n",
        "def convert_emojis(text):\n",
        "    if isinstance(text, str):\n",
        "        return emoji.demojize(text)\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "df_data['text'] = df_data['text'].apply(convert_emojis)\n",
        "\n",
        "#Function to remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    if isinstance(text, str):\n",
        "        tokens = word_tokenize(text)\n",
        "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "        return ' '.join(filtered_tokens)\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "#Apply stop word removal to the text column\n",
        "df_data['text'] = df_data['text'].apply(remove_stop_words)\n",
        "\n",
        "#Function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        return word_tokenize(text)\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "#Apply tokenization to the text column\n",
        "df_data['tokens'] = df_data['text'].apply(tokenize_text)\n",
        "\n",
        "#Function to lemmatize tokens\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    if isinstance(tokens, list):\n",
        "        return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    else:\n",
        "        return tokens\n",
        "\n",
        "#Apply lemmatization to the tokens column\n",
        "df_data['lemmatized_tokens'] = df_data['tokens'].apply(lemmatize_tokens)\n",
        "\n",
        "#Join lemmatized tokens back into strings\n",
        "df_data['lemmatized_text'] = df_data['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "#Function to remove null values\n",
        "def remove_null_values(df, column_name):\n",
        "    df = df.dropna(subset=[column_name])\n",
        "    return df\n",
        "\n",
        "#Apply null value removal to the lemmatized text column\n",
        "df_data = remove_null_values(df_data, 'lemmatized_text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7WahyjwKsJ3"
      },
      "outputs": [],
      "source": [
        "#Join the lemmatized tokens back into a single string\n",
        "df_data['processed_text'] = df_data['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFlquLD9Kn01"
      },
      "source": [
        "### **Vectorization and Train-Test Split**\n",
        "\n",
        "A vectorizer converts our text column into tokens and then converts the tokens into numerical vectors.  \n",
        "\n",
        "We imported **TfidVectorizer** which implements vectorization by converting text into a matrix of TF-IDF (Term Frequency-Inverse Document Frequency) features. This matrix quantifies the importance of each word in a document relative to the entire corpus, helping to highlight words that are more relevant to each document.  \n",
        "\n",
        "Next, we will do the test-train split: 70% of the dataset will be used for training the model and the remaining 30% is used for testing. We imported the **train_test_split** function from scikit-learn module. This separation helps ensure that the model's performance metrics are reliable and that it doesn't overfit to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbjCIKa8KuL1"
      },
      "outputs": [],
      "source": [
        "#Split the dataframe into inputs and expected outputs\n",
        "x = df_data['processed_text']\n",
        "y = df_data['label']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Split x and y into training sets and test sets\n",
        "#Split the dataset into 70% training and 30% testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=4)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#Initialize CountVectorizer and fit on training data\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "#Transform the training and test data\n",
        "x_train_vectorized = vectorizer.transform(x_train)\n",
        "x_test_vectorized = vectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maUP1ppGK-BO"
      },
      "source": [
        "## **Model Training**\n",
        "\n",
        "We have decided to use the three different types of Naive Bayes Classifier which is the Multinomial, Complement and Bernoulli model and we will compare which model has the best accuracy. We have also calculated the confusion matrix and classification report to help us compare.\n",
        "1. Accuracy is defined as the porprotion of correct predictions made by the model out of the total number of predictions.\n",
        "2. The confusion matrix summarizes a classification model's performance by showing true positives, true negatives, false positives, and false negatives.\n",
        "3. The classification report offers a comprehensive summary of a model's performance by detailing key metrics such as precision (accuracy of positive predictions), recall (ability to identify all positive cases), F1-score (the harmonic mean of precision and recall), and support (the number of actual instances of each class). It provides an overall evaluation of how well the model performs across different classes, balancing precision and recall to give a clear picture of its effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGdMlbO7XzGI"
      },
      "source": [
        "### **Multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdWhRuUHK9Rd",
        "outputId": "b6c9d831-c75b-4cd3-cc61-689dd7b7cd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB model accuracy is 69.51%\n",
            "------------------------------------------------\n",
            "Confusion Matrix:\n",
            "      0     1     2\n",
            "0  1709  1708   163\n",
            "1   205  4291   446\n",
            "2    47  1220  2639\n",
            "------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.48      0.62      3580\n",
            "           1       0.59      0.87      0.71      4942\n",
            "           2       0.81      0.68      0.74      3906\n",
            "\n",
            "    accuracy                           0.70     12428\n",
            "   macro avg       0.76      0.67      0.69     12428\n",
            "weighted avg       0.74      0.70      0.69     12428\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Train a naive bayes classifier: MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train_vectorized, y_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "mnb_predicted = mnb.predict(x_test_vectorized)\n",
        "accuracy_score_mnb = metrics.accuracy_score(y_test, mnb_predicted)\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train_vectorized, y_train)\n",
        "\n",
        "print('MultinomialNB model accuracy is',str('{:04.2f}'.format(accuracy_score_mnb*100))+'%')\n",
        "print('------------------------------------------------')\n",
        "print('Confusion Matrix:')\n",
        "print(pd.DataFrame(confusion_matrix(y_test, mnb_predicted)))\n",
        "print('------------------------------------------------')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, mnb_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8HhloJ-LSjX"
      },
      "source": [
        "### **ROC AUC Score**\n",
        "\n",
        "Here we are calculating the ROC AUC score which tells how good the models are at identifying instances the 3 different classes: Negative, Neutral and Positive sentiments.\n",
        "\n",
        "The ROC (Receiver Operating Characteristic) curve visually represents a model's performance by plotting the true positive rate against the false positive rate at various classification thresholds. It helps assess the trade-off between sensitivity (true positives) and specificity (false positives). A model with a curve closer to the top left corner indicates better performance, and the area under the curve (AUC) quantifies overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2FtQXdCLUfk",
        "outputId": "cdf1c4a3-d267-4ef7-b1b3-bf452c4cd0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Multinomial ROC AUC Score: 0.8656\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#Compare probabilities and ROC AUC score\n",
        "MNB_prob = mnb.predict_proba(x_test_vectorized)\n",
        "roc_auc_mnb = roc_auc_score(y_test, MNB_prob, multi_class='ovr')\n",
        "print(f'Naive Bayes Multinomial ROC AUC Score: {roc_auc_mnb:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXW24GqfXzGM"
      },
      "source": [
        "## **Hyperparemeter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hskTHgKXLojE",
        "outputId": "267f7a38-e89c-49a9-d277-f91790c06d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'alpha': 0.5}\n",
            "Best Cross-Validation Score: 0.6841853530037877\n",
            "Best Hyperparameters: {'alpha': 0.5}\n",
            "Accuracy for multinomial model: 70.95268747988413%\n",
            "ROC AUC Score: 0.8730\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]\n",
        "}\n",
        "\n",
        "#Perform GridSearchCV on multinomial model\n",
        "grid_search = GridSearchCV(mnb, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train_vectorized, y_train)\n",
        "\n",
        "#Print the best parameters and best score\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")\n",
        "\n",
        "#Get the best model and hyperparameters\n",
        "best_clf = grid_search.best_estimator_\n",
        "print(f'Best Hyperparameters: {grid_search.best_params_}')\n",
        "\n",
        "#Make predictions on the test set with the best model\n",
        "predictionsMNB = best_clf.predict(x_test_vectorized)\n",
        "\n",
        "#Retrain the model using the best parameters\n",
        "MNB_best_model = grid_search.best_estimator_\n",
        "MNB_best_model.fit(x_train_vectorized, y_train)\n",
        "\n",
        "#Calculate the accuracy\n",
        "accuracyMNB = accuracy_score(y_test, predictionsMNB)\n",
        "print(f'Accuracy for multinomial model: {accuracyMNB * 100}%')\n",
        "\n",
        "#Calculate ROC AUC Score\n",
        "MNB_prob = best_clf.predict_proba(x_test_vectorized)\n",
        "MNB_roc_auc = roc_auc_score(y_test, MNB_prob, multi_class='ovr')\n",
        "print(f'ROC AUC Score: {MNB_roc_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y94yR0fULymo",
        "outputId": "6362c895-eece-477c-9eb3-756ae255692e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: MNB\n",
            "ROC AUC Score: 0.8730\n",
            "Accuracy: 0.7095\n"
          ]
        }
      ],
      "source": [
        "#Set roc_auc to best model\n",
        "roc_auc = MNB_roc_auc\n",
        "\n",
        "#Determine the best model based on roc_auc\n",
        "best_model = \"MNB\"\n",
        "\n",
        "#Set predictions to best model\n",
        "predictions = globals()[f\"predictions{best_model}\"]\n",
        "\n",
        "#Set accuracy to best model\n",
        "accuracy = globals()[f\"accuracy{best_model}\"]\n",
        "\n",
        "print(f'Best Model: {best_model}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lizyhfmhbxvd"
      },
      "source": [
        "## **Transformer Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRKzDUQUXzGR",
        "outputId": "a281482a-4ba5-4ba6-fc89-130f026fecda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(MNB_best_model, 'naive_bayes_model.pkl')\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7ZkPiztXzGR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDzUhur4XzGR"
      },
      "outputs": [],
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS_B7WOZXzGR",
        "outputId": "ceb1265f-9833-4c5a-b60a-d95a252c3212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7d1a3ea17550>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenizer(x_train.tolist(), truncation=True, padding='max_length', max_length=514, return_tensors='pt')\n",
        "test_encodings = tokenizer(x_test.tolist(), truncation=True, padding='max_length', max_length=514, return_tensors='pt')\n",
        "\n",
        "# Convert to torch Dataset\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}  # Adjusted tensor creation\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, y_train.tolist())\n",
        "test_dataset = SentimentDataset(test_encodings, y_test.tolist())\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMwe5b2fXzGS"
      },
      "outputs": [],
      "source": [
        "# Function to calculate ROC AUC score and accuracy\n",
        "def compute_metrics(model, dataset):\n",
        "    trainer = Trainer(model=model)\n",
        "    predictions = trainer.predict(dataset)\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()\n",
        "\n",
        "    # Compute predicted classes\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Compute ROC AUC score for multiclass classification\n",
        "    roc_auc = roc_auc_score(dataset.labels, probs, multi_class='ovr')\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(dataset.labels, preds)\n",
        "\n",
        "    return roc_auc, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "zLFheHuvXzGS",
        "outputId": "36e8a502-0d59-4de0-82c1-8a3f9101e691"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score before fine-tuning: 0.848275680533778\n",
            "Accuracy before fine-tuning: 0.6901351786289025\n"
          ]
        }
      ],
      "source": [
        "# Calculate ROC AUC score and accuracy before fine-tuning\n",
        "roc_auc_before, accuracy_before = compute_metrics(model, test_dataset)\n",
        "print(f\"ROC AUC Score before fine-tuning: {roc_auc_before}\")\n",
        "print(f\"Accuracy before fine-tuning: {accuracy_before}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ehiS0iQXzGS",
        "outputId": "12cd9dd6-b30e-41dd-c3c1-5413d07df2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    max_grad_norm=1.0\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "2c6lwfd_XzGc",
        "outputId": "7076cf3c-366f-4cde-87d5-ba345f93b577"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='336' max='1359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 336/1359 15:26 < 47:19, 0.36 it/s, Epoch 0.74/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1359' max='1359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1359/1359 1:06:29, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.471600</td>\n",
              "      <td>0.593001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.331800</td>\n",
              "      <td>0.598337</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1359, training_loss=0.4668948587202868, metrics={'train_runtime': 3992.0374, 'train_samples_per_second': 21.792, 'train_steps_per_second': 0.34, 'total_flos': 2.2960210061348784e+16, 'train_loss': 0.4668948587202868, 'epoch': 2.9966923925027564})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsIcqMqKXzGc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "c5d542e8-7d3a-43e8-f4d3-486e47a895f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-973a3b1f10b7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save only the model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_weights_3_epoch.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# To load the weights later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = AutoModelForSequenceClassification.from_pretrained(MODEL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# Save only the model weights\n",
        "torch.save(model.state_dict(), 'model_weights_3_epoch.pth')\n",
        "\n",
        "# To load the weights later\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "# model.load_state_dict(torch.load('model_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "HUGA_Z7VXzGd",
        "outputId": "db262905-5bf5-4369-c19b-bba4f652aaed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score after fine-tuning: 0.9242\n",
            "Accuracy after fine-tuning: 0.7988\n"
          ]
        }
      ],
      "source": [
        "# Calculate ROC AUC score and accuracy after fine-tuning\n",
        "roc_auc_after, accuracy_after = compute_metrics(model, test_dataset)\n",
        "print(f\"ROC AUC Score after fine-tuning: {roc_auc_after:.4f}\")\n",
        "print(f\"Accuracy after fine-tuning: {accuracy_after:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}